MODEL:
  META_ARCHITECTURE: "RelationRetinaNet"
  BACKBONE:
    NAME: "build_retinanet_resnet_fpn_backbone"
  WEIGHTS: "./output/model_0048699.pth"
  #WEIGHTS: "./output/model_0014999.pth"

  RESNETS:
    OUT_FEATURES: ["res3", "res4", "res5"]
    DEPTH: 50
  ANCHOR_GENERATOR:
    NAME: "RotatedAnchorGenerator"
    #SIZES: !!python/object/apply:eval ["[[x, x * 2**(1.0/3), x * 2**(2.0/3) ] for x in [32, 64, 128, 256, 512]]"]
    SIZES: [[16, 32, 64]]
    ASPECT_RATIOS: [[0.25, 1, 2]]
    #ANGLES: [[-90, -75, -60, -45, -30, -15, 0, 15, 30, 45, 60, 75, 90]]
    ANGLES: [[-90, -45, 0, 45, 90]]
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]
  RPN:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0, 0.8)
  RETINANET:
    IOU_THRESHOLDS: [0.4, 0.6]
    IOU_LABELS: [0, -1, 1]
    NUM_CLASSES: 4
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
DATASETS:
  TRAIN: ("pathway_train_0",)
  TEST: ("pathway_val_0",)
SOLVER:
  IMS_PER_BATCH: 2
  CHECKPOINT_PERIOD: 100
  MOMENTUM: 0.9
  BASE_LR: 0.01  # Note that RetinaNet uses a different default learning rate
  STEPS: (210000, 250000)
  MAX_ITER: 270000
INPUT:
  MIN_SIZE_TRAIN: (320, 480, 640, 672, 736, 768, 800)
  MAX_SIZE_TRAIN: 1000
TEST:
  EVAL_PERIOD: 0